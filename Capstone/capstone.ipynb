{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    '''\n",
    "    remove redundant columns\n",
    "    '''\n",
    "    #rems = ['Id', 'Soil_Type7', 'Soil_Type8', 'Soil_Type15', 'Soil_Type25']\n",
    "    rems = ['Id', 'Soil_Type7', 'Soil_Type15']\n",
    "#     #Add constant columns as they don't help in prediction process\n",
    "#     for c in data.columns:\n",
    "#         if data[c].std() == 0: #standard deviation is zero\n",
    "#             rem.append(c)\n",
    "\n",
    "    #drop the columns\n",
    "    for rem in rems:\n",
    "        data.drop(rem,axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(y, y_pred):\n",
    "\n",
    "    y_true = np.array(y, dtype=int)\n",
    "    y_predict = np.array(y_pred, dtype=int)\n",
    "    \n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    return f1_score(y_true, y_predict, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def normalize_train_data(dataset):\n",
    "    r, c = dataset.shape\n",
    "    array = dataset.values\n",
    "    X_all = array[:,0:(c-1)]\n",
    "    y_all = array[:,(c-1)]\n",
    "    size = 10\n",
    "    X_num = X_all[:,0:size]\n",
    "    X_cat = X_all[:,size:]\n",
    "\n",
    "    X_num = StandardScaler().fit_transform(X_num)\n",
    "    X_num = MinMaxScaler().fit_transform(X_num)\n",
    "    X_num = Normalizer().fit_transform(X_num)\n",
    "\n",
    "    X_all_scaled = np.concatenate((X_num, X_cat), axis=1)\n",
    "    \n",
    "    return X_all_scaled, y_all\n",
    "\n",
    "def normalize_test_data(dataset):\n",
    "    r, c = dataset.shape\n",
    "    X_all = dataset.values\n",
    "    y_all = []\n",
    "    size = 10\n",
    "    X_num = X_all[:,0:size]\n",
    "    X_cat = X_all[:,size:]\n",
    "\n",
    "    X_num = StandardScaler().fit_transform(X_num)\n",
    "    X_num = MinMaxScaler().fit_transform(X_num)\n",
    "    X_num = Normalizer().fit_transform(X_num)\n",
    "\n",
    "    X_all_scaled = np.concatenate((X_num, X_cat), axis=1)\n",
    "    \n",
    "    return X_all_scaled, y_all\n",
    "\n",
    "def train_extract(train, test):\n",
    "    X_train, y_train = normalize_train_data(train)\n",
    "    X_test, y_test = normalize_train_data(test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_cross_validation(model, train):\n",
    "    '''Performs a kfold cross validation of a given model'''\n",
    "    kfold_train_test = []\n",
    "    extracted_features = []\n",
    "    kf = StratifiedKFold(train[\"Cover_Type\"], n_folds=10)\n",
    "    for train_index, test_index in kf:\n",
    "        train_kfold = train.loc[train_index]\n",
    "        test_kfold = train.loc[test_index]\n",
    "        extracted_features.append(tuple(train_extract(train_kfold, test_kfold)))\n",
    "    score_count = 0\n",
    "    score_total = 0.0\n",
    "    submission = []\n",
    "    print (model)\n",
    "    for X_train, y_train, X_test, y_test in extracted_features:\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        #score = model.score(X_test, y_test)\n",
    "        predictions = model.predict(X_test)\n",
    "        score = f1_score(y_test, predictions, average='micro')\n",
    "        test_data = pd.DataFrame({'id': y_test, 'predictions': predictions})\n",
    "        submission.append(test_data)\n",
    "        score_count += 1\n",
    "        score_total += score\n",
    "        print(\"Kfold score \" + str(score_count) + \": \" + str(score))\n",
    "    average_score = score_total/float(score_count)\n",
    "    print(\"Average score: \" + str(average_score))\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_predictions(model, train, test):\n",
    "    '''\n",
    "    Performs the final prediction on test dataset\n",
    "    '''\n",
    "    global Id\n",
    "    \n",
    "    submission = []\n",
    "    X_train, y_train = normalize_train_data(train)\n",
    "    X_test, y_test = normalize_test_data(test)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    final_predictions = model.predict(X_test)\n",
    "    \n",
    "    test_data = pd.DataFrame({'Id': Id, 'Cover_Type': final_predictions})\n",
    "    submission.append(test_data)\n",
    "    #submission = pd.DataFrame({'id': test_clean['id'], 'prediction': weighted_prediction})\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_csv(df,out):\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    df.to_csv(out, index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Cleaning data...\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "Kfold score 1: 0.634259259259\n",
      "Kfold score 2: 0.67328042328\n",
      "Kfold score 3: 0.699735449735\n",
      "Kfold score 4: 0.640211640212\n",
      "Kfold score 5: 0.622354497354\n",
      "Kfold score 6: 0.636243386243\n",
      "Kfold score 7: 0.67791005291\n",
      "Kfold score 8: 0.664021164021\n",
      "Kfold score 9: 0.787698412698\n",
      "Kfold score 10: 0.739417989418\n",
      "Average score: 0.677513227513\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=18, n_jobs=-1, oob_score=False, random_state=19,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold score 1: 0.575396825397\n",
      "Kfold score 2: 0.664021164021\n",
      "Kfold score 3: 0.672619047619\n",
      "Kfold score 4: 0.560846560847\n",
      "Kfold score 5: 0.611111111111\n",
      "Kfold score 6: 0.626984126984\n",
      "Kfold score 7: 0.617063492063\n",
      "Kfold score 8: 0.674603174603\n",
      "Kfold score 9: 0.757936507937\n",
      "Kfold score 10: 0.706349206349\n",
      "Average score: 0.646693121693\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=19,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold score 1: 0.587301587302\n",
      "Kfold score 2: 0.649470899471\n",
      "Kfold score 3: 0.649470899471\n",
      "Kfold score 4: 0.547619047619\n",
      "Kfold score 5: 0.594576719577\n",
      "Kfold score 6: 0.607804232804\n",
      "Kfold score 7: 0.568783068783\n",
      "Kfold score 8: 0.654100529101\n",
      "Kfold score 9: 0.738756613757\n",
      "Kfold score 10: 0.686507936508\n",
      "Average score: 0.628439153439\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/brandon/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembling...\n",
      "Best set of weights: None\n",
      "Corresponding score: 0.68\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-44534996ecb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Corresponding score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_average_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mweighted_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cover_Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mweighted_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweighted_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cover_Type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweighted_prediction\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-44534996ecb9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Corresponding score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_average_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mweighted_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cover_Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mweighted_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweighted_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cover_Type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweighted_prediction\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cross_validation import KFold, StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print ('Loading data...')\n",
    "    train_raw = pd.read_csv('data/train.csv')\n",
    "    test_raw = pd.read_csv('data/test.csv')\n",
    "    Id = test_raw['Id']\n",
    "    print ('Cleaning data...')\n",
    "    train_clean = process_data(train_raw)\n",
    "    test_clean = process_data(test_raw)\n",
    "\n",
    "\n",
    "    print ('Training...')\n",
    "\n",
    "    seed = 19\n",
    "\n",
    "    model_0 = KNeighborsClassifier(n_jobs=-1, algorithm='auto',n_neighbors=1)\n",
    "    model_1 = RandomForestClassifier(n_jobs=-1, n_estimators=18, random_state=seed)\n",
    "    model_2 = GradientBoostingClassifier(max_depth=8, random_state=seed)\n",
    "    \n",
    "    cv_pred_1 = perform_cross_validation(model_0, train_clean)\n",
    "    cv_pred_2 = perform_cross_validation(model_1, train_clean)\n",
    "    cv_pred_3 = perform_cross_validation(model_2, train_clean)\n",
    "    \n",
    "    print ('Predicting...')\n",
    "    pred_1 = perform_predictions(model_0, train_clean, test_clean)\n",
    "    pred_2 = perform_predictions(model_1, train_clean, test_clean)\n",
    "    pred_3 = perform_predictions(model_2, train_clean, test_clean)\n",
    "\n",
    "    print ('Ensembling...')\n",
    "    cv_preds = [cv_pred_1, cv_pred_2, cv_pred_3]\n",
    "    wt_final = []\n",
    "    for i in range(1500):\n",
    "        w = np.random.dirichlet(np.ones(3),size=1)\n",
    "        wt_final.append(w)\n",
    "    max_average_score = 0.68\n",
    "    max_weights = None\n",
    "    for wt in wt_final:\n",
    "        total_score = 0\n",
    "        for i in range(9):\n",
    "            y_true = cv_preds[0][i]['id']\n",
    "            weighted_prediction = sum([wt[0][x] * cv_preds[x][i]['predictions'].astype(int).reset_index() for x in range(3)])\n",
    "            weighted_prediction = [round(p) for p in weighted_prediction['predictions']]\n",
    "            total_score += score(y_true, weighted_prediction)\n",
    "        average_score = total_score/9.0\n",
    "        if (average_score > max_average_score):\n",
    "            max_average_score = average_score\n",
    "            max_weights = wt\n",
    "    print ('Best set of weights: ' + str(max_weights))\n",
    "    print ('Corresponding score: ' + str(max_average_score))\n",
    "    preds = [pred_1, pred_2, pred_3]\n",
    "    weighted_prediction = sum([max_weights[0][x] * preds[x][0]['Cover_Type'].astype(int) for x in range(3)])\n",
    "    weighted_prediction = [int(round(p)) for p in weighted_prediction]\n",
    "    submission = pd.DataFrame({'Id': Id, 'Cover_Type': weighted_prediction})\n",
    "    #submission.to_csv('submission.csv', index=False)\n",
    "    to_csv(submission, 'submission.csv')\n",
    "    print('Output submission file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembling...\n",
      "Best set of weights: [[ 0.00634345  0.94818049  0.04547606]]\n",
      "Corresponding score: 0.687698412698\n",
      "Output submission file\n"
     ]
    }
   ],
   "source": [
    "    print ('Ensembling...')\n",
    "    cv_preds = [cv_pred_1, cv_pred_2, cv_pred_3]\n",
    "    wt_final = []\n",
    "    for i in range(1000):\n",
    "        w = np.random.dirichlet(np.ones(3)/10,size=1)\n",
    "        wt_final.append(w)\n",
    "    max_average_score = 0.68\n",
    "    max_weights = None\n",
    "    for wt in wt_final:\n",
    "        total_score = 0\n",
    "        for i in range(10):\n",
    "            for x in range(3):\n",
    "                y_true = cv_preds[x][i]['id']\n",
    "                weighted_prediction = sum([wt[0][x] * cv_preds[x][i]['predictions'].astype(int).reset_index()])\n",
    "                weighted_prediction = [round(p) for p in weighted_prediction['predictions']]\n",
    "                #print(weighted_prediction)\n",
    "                total_score += score(y_true, weighted_prediction)\n",
    "                #print(total_score)\n",
    "            average_score = total_score/10.0\n",
    "            if (average_score > max_average_score):\n",
    "                max_average_score = average_score\n",
    "                max_weights = wt\n",
    "    print ('Best set of weights: ' + str(max_weights))\n",
    "    print ('Corresponding score: ' + str(max_average_score))\n",
    "    \n",
    "    preds = [pred_1, pred_2, pred_3]\n",
    "    weighted_prediction = sum([max_weights[0][x] * preds[x][0]['Cover_Type'].astype(int) for x in range(3)])\n",
    "    weighted_prediction = [int(round(p)) for p in weighted_prediction]\n",
    "    submission = pd.DataFrame({'Id': Id, 'Cover_Type': weighted_prediction})\n",
    "    #submission.to_csv('submission.csv', index=False)\n",
    "    to_csv(submission, 'submission.csv')\n",
    "    print('Output submission file')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
